# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p85FWcmog01MGh5ImsP4CHgG5RkO-GH6
"""

from flask import Flask, request, jsonify
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
from transformers import BartForConditionalGeneration, BartTokenizer
import torch
import nltk
import re
import string

# Initialize the Flask app
app = Flask(__name__)

# Setup for Extractive Summarization (TextRank)
nltk.download('punkt')
extractive_embedder = SentenceTransformer('all-mpnet-base-v2')

# Setup for Abstractive Summarization (BART)
device = "cuda" if torch.cuda.is_available() else "cpu"
abstractive_model = BartForConditionalGeneration.from_pretrained("facebook/bart-large-cnn").to(device)
abstractive_tokenizer = BartTokenizer.from_pretrained("facebook/bart-large-cnn")


def clean_text(text):
    if isinstance(text, str):
        text = text.lower()
        text = re.sub(r'\d+', '', text)
        text = text.translate(str.maketrans('', '', string.punctuation))
        text = re.sub(r'\s+', ' ', text).strip()
    return text


def preprocess_text(text):
    return [s.strip() for s in nltk.sent_tokenize(text) if len(s) > 20]


def build_similarity_matrix(embeddings, threshold=0.3):
    sim_matrix = cosine_similarity(embeddings)
    sim_matrix[sim_matrix < threshold] = 0
    return sim_matrix


# Extractive Summarizer
def extractive_summarize(text, num_sentences=3):
    sentences = preprocess_text(text)
    if len(sentences) <= num_sentences:
        return ' '.join(sentences)

    embeddings = extractive_embedder.encode(sentences, convert_to_tensor=True)
    sim_matrix = build_similarity_matrix(embeddings.cpu().numpy())

    nx_graph = nx.from_numpy_array(sim_matrix)
    scores = nx.pagerank(nx_graph)
    ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)

    return ' '.join([s for _, s in ranked[:num_sentences]])


# Abstractive Summarizer (BART)
def abstractive_summarize(text, max_length=150, min_length=30):
    inputs = abstractive_tokenizer(text, return_tensors="pt", truncation=True, max_length=1024).to(device)
    summary_ids = abstractive_model.generate(inputs["input_ids"], max_length=max_length, min_length=min_length, num_beams=4)
    return abstractive_tokenizer.decode(summary_ids[0], skip_special_tokens=True)


@app.route('/summarize', methods=['POST'])
def summarize_email():
    data = request.json
    email_content = data.get('email_content')
    from_email = data.get('from_email')
    received_date = data.get('received_date')
    received_time = data.get('received_time')
    action_to_take = data.get('action_to_take')

    # Summarize email using both methods
    extractive_summary = extractive_summarize(email_content)
    abstractive_summary = abstractive_summarize(email_content)

    # Construct response
    result = {
        'From': from_email,
        'Date': received_date,
        'Time': received_time,
        'Action': action_to_take,
        'Extractive Summary': extractive_summary,
        'Abstractive Summary': abstractive_summary
    }

    return jsonify(result)


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)